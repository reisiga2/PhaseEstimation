%S=expectedStates(mc,T,startState)
%Returns the "expected state sequence" from the given MarkovChain object.
%This is generated by staying in each state for the expected duration, and
%then picking the most likely successor.
%
%Input:
%mc= MarkovChain object
%T= scalar defining maximum length of desired state sequence.
%   An infinite-duration MarkovChain always generates sequence of length=T
%   A finite-duration MarkovChain may return a shorter sequence,
%   if the END state was reached before T samples.
%startState= First state of sequence (optional).
%
%Result:
%S= integer row vector with expected state sequence,
%   NOT INCLUDING the END state,
%   even if encountered within T samples
%If mc has INFINITE duration,
%   length(S) == T
%If mc has FINITE duration,
%   length(S) <= T
%
%Gustav Eje Henter 2011-11-23 untested

function S=expectedStates(mc,T,state)
nStates=length(mc.InitialProb);
durations = meanStateDuration(mc);
if (nargin < 3) || isempty(T),
    T = sum(durations);
end
T = ceil(T);
S=zeros(1,T);
if (nargin < 3),
    [~,state] = max(mc.InitialProb);
end
t = 0;
while (t+0.5 <= T),
    dur = durations(state);
    ts = ceil(t+0.5):min(T,floor(t+0.5+dur));
    S(ts) = state;
    t = t + dur;
    
    successorProbs = mc.TransitionProb(state,:);
    successorProbs(state) = 0;
    [~,state] = max(successorProbs);
    if (state > nStates),
        S = S(1:ts(end));
        break; % END state reached
    end
end